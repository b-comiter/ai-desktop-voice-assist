# Desktop Voice Assistant

A local AI-powered voice assistant that lets you interact naturally with your computer. Speak to it, and it listens, thinks, and responds â€” just like a personal AI agent running on your machine.

## âœ¨ Features

* **Voice Interaction**: Speak naturally to the assistant, and get spoken responses back.
* **Local Processing**: Uses Ollama and other local tools â€” your data stays on your device.
* **Computer Control**: The assistant can open apps, play music, and more using JSON-based commands.
* **Benchmarking**: Built-in testing framework to compare different models and measure performance.

## ğŸ›  System Overview

The system is composed of three main parts:

1. **Transcriber**: Converts your voice to text in real-time.
2. **LLM Agent**: Processes text input, decides how to respond, and can issue JSON commands.
3. **Voice Synthesizer**: Converts responses back into natural-sounding speech.

This flow makes the assistant function like OpenAIâ€™s voice assistant, but fully local.

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ desktop-voice-assist/
â”‚   â”œâ”€â”€ uv.lock
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ print_structure.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ .python-version
â”‚   â”œâ”€â”€ benchmarks/
â”‚   â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”‚   â”œâ”€â”€ benchmark_trancription.py
â”‚   â”‚   â”‚   â”œâ”€â”€ benchmark_models .py
â”‚   â”‚   â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ context.json           # Created on Startup
â”‚   â”‚   â”œâ”€â”€ samples/
â”‚   â”‚   â”œâ”€â”€ audio_input/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ voice_assist/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tools.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ get_active_apps.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ai_agent.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm_process.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm_stream.py
â”‚   â”‚   â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ multiprocess_pipeline.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ voice_assistant_pipeline.py
â”‚   â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ context_manager.py
â”‚   â”‚   â”‚   â”œâ”€â”€ transacription/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ transcriber.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ auto_spliter.py
â”‚   â”‚   â”‚   â”œâ”€â”€ voice/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ voice_process.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ voice_synth.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ voice_stream.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ kokoro/                # Stores the kokoro files that the voice synthesizer uses
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ kokoro-v1.0.onnx
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ voices-v1.0.bin
```

## ğŸš€ Getting Started

## Setup

Please review the instructions below

<details>

<summary>Instructions</summary>

1. Install [uv](https://docs.astral.sh/uv/getting-started/installation) for isolated Python (Recommend).

```console
pip install uv
```

2. Download the repo
   
3. From the repo
   
    ```console
    uv sync
    ```
   
4. Download the files [`kokoro-v1.0.onnx`](https://github.com/thewh1teagle/kokoro-onnx/releases/download/model-files-v1.0/kokoro-v1.0.onnx), and [`voices-v1.0.bin`](https://github.com/thewh1teagle/kokoro-onnx/releases/download/model-files-v1.0/voices-v1.0.bin) and place them into the src/voice_assist/voice/kokoro

5. Run

```console
uv run main.py
```

</details>

</details>

### Prerequisites

* Python 3.11+
* [Ollama](https://ollama.ai) installed and configured

### Run the Assistant

```bash
uv sync 
uv run main.py
```

### Example Interaction

* You: "open Google Chrome."
* Assistant â†’ JSON: `{ "type": "open_app", "name": "Google Chrome" }`

## ğŸ“Š Benchmarks

The `benchmarks` folder contains tools for testing different models. Run benchmarks with:

This will output performance metrics for speed, accuracy, and responsiveness.

## ğŸ¤ Contributing

Contributions are welcome! Feel free to submit pull requests for:

* New features
* Bug fixes
* Model integrations
* Benchmarks improvements

## ğŸ“„ License

kokoro-onnx: MIT
kokoro model: Apache 2.0
